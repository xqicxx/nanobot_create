#!/usr/bin/env python3
"""
memu-py æ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•ä¸åŒæ“ä½œçš„å“åº”æ—¶é—´
"""

import os
import sys
import time
from pathlib import Path

# ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ
VENV_PYTHON = "/root/nanobot-venv/bin/python"
if os.path.exists(VENV_PYTHON) and os.path.abspath(sys.executable) != os.path.abspath(VENV_PYTHON):
    os.execv(VENV_PYTHON, [VENV_PYTHON, __file__] + sys.argv[1:])

sys.path.insert(0, "/root/nanoBot_memU/nanobot")

from nanobot.config.loader import load_config
from nanobot.agent.memory_adapter import MemoryAdapter

def test_llm_speed():
    """æµ‹è¯• LLM å“åº”é€Ÿåº¦"""
    print("\n" + "=" * 50)
    print("æµ‹è¯• LLM å“åº”é€Ÿåº¦")
    print("=" * 50)

    from memu.llm import DeepSeekClient

    config = load_config()
    memu_cfg = config.memu
    default_cfg = getattr(memu_cfg, "default", None)

    if not default_cfg:
        print("âŒ æœªæ‰¾åˆ° MemU é…ç½®")
        return

    api_key = os.environ.get("DEEPSEEK_API_KEY", "") or getattr(default_cfg, "api_key", "")
    base_url = getattr(default_cfg, "base_url", "https://api.deepseek.com/v1")
    chat_model = getattr(default_cfg, "chat_model", "deepseek-chat")

    print(f"æ¨¡å‹: {chat_model}")
    print(f"API: {base_url}")

    client = DeepSeekClient(
        api_key=api_key,
        base_url=base_url,
        model_name=chat_model,
    )

    # æµ‹è¯•1: ç®€å•è¯·æ±‚
    print("\nğŸ“ æµ‹è¯•1: ç®€å•è¯·æ±‚ (1å¥è¯)")
    start = time.perf_counter()
    try:
        response = client.chat.completions.create(
            model=chat_model,
            messages=[{"role": "user", "content": "ä½ å¥½"}],
            max_tokens=20,
        )
        elapsed = time.perf_counter() - start
        print(f"âœ… è€—æ—¶: {elapsed:.2f}ç§’")
        print(f"   å›å¤: {response.choices[0].message.content[:50]}")
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")

    # æµ‹è¯•2: å¤æ‚è¯·æ±‚ï¼ˆæ¨¡æ‹Ÿè®°å¿†å¤„ç†ï¼‰
    print("\nğŸ“ æµ‹è¯•2: å¤æ‚è¯·æ±‚ (æ¨¡æ‹Ÿè®°å¿†åˆ†æ)")
    conversation = [
        {"role": "user", "content": "æˆ‘ä»Šå¤©å­¦ä¼šäº† Python ç¼–ç¨‹ï¼Œç‰¹åˆ«å¼€å¿ƒï¼æˆ‘è¿˜è®¤è¯†äº†æ–°æœ‹å‹å°æ˜ï¼Œä»–æ•™æˆ‘å†™ä»£ç ã€‚"},
        {"role": "assistant", "content": "å¤ªæ£’äº†ï¼Python æ˜¯å¾ˆæœ‰ç”¨çš„ç¼–ç¨‹è¯­è¨€ï¼Œæ­å–œä½ å­¦ä¼šäº†ï¼å°æ˜ä¹Ÿæ˜¯å¾ˆå¥½çš„æœ‹å‹ã€‚"},
    ]
    start = time.perf_counter()
    try:
        response = client.chat.completions.create(
            model=chat_model,
            messages=[
                {"role": "system", "content": "åˆ†æè¿™æ®µå¯¹è¯ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚"},
                *conversation,
            ],
            max_tokens=100,
        )
        elapsed = time.perf_counter() - start
        print(f"âœ… è€—æ—¶: {elapsed:.2f}ç§’")
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")

def test_memory_agent():
    """æµ‹è¯• MemoryAgent é€Ÿåº¦"""
    print("\n" + "=" * 50)
    print("æµ‹è¯• MemoryAgent é€Ÿåº¦")
    print("=" * 50)

    config = load_config()
    adapter = MemoryAdapter(
        workspace=config.workspace_path,
        memu_config=config.memu,
    )

    if not adapter._memory_agent:
        print("âŒ MemoryAgent æœªåˆå§‹åŒ–")
        return

    # æµ‹è¯•è®°å¿†å¤„ç†é€Ÿåº¦
    print("\nğŸ“ æµ‹è¯•è®°å¿†å¤„ç†...")
    conversation = [
        {"role": "user", "content": "æµ‹è¯•æ¶ˆæ¯ï¼šä»Šå¤©å¤©æ°”çœŸå¥½ï¼"},
        {"role": "assistant", "content": "æ˜¯å•Šï¼Œå¾ˆé€‚åˆå‡ºå»èµ°èµ°ã€‚"},
    ]

    import asyncio
    start = time.perf_counter()
    asyncio.run(adapter.memorize_turn(
        channel="test",
        chat_id="speed-test",
        sender_id="test-user",
        user_message=conversation[0]["content"],
        assistant_message=conversation[1]["content"],
    ))
    elapsed = time.perf_counter() - start
    print(f"âœ… æ€»è€—æ—¶: {elapsed:.2f}ç§’")

if __name__ == "__main__":
    test_llm_speed()
    test_memory_agent()
    print("\n" + "=" * 50)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 50)
